<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Wang Chuan&#39;s Homepage by wangchuan</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Wang Chuan&#39;s Homepage</h1>
      <h2 class="project-tagline"></h2>
    </section>

    <section class="main-content">
      <h2>
<a id="dr-chuan-wang" class="anchor" href="#dr-chuan-wang" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dr. Chuan Wang</h2>

<p><em>Specialise in Computer Vision and Image/Video Processing</em></p>

<h3>
<a id="contact" class="anchor" href="#contact" aria-hidden="true"><span class="octicon octicon-link"></span></a>Contact</h3>

<ul>
<li>Phone: (+852) 5162 6756</li>
<li>Email: wangchuan2400 (at) gmail (dot) com</li>
</ul>

<h3>
<a id="education" class="anchor" href="#education" aria-hidden="true"><span class="octicon octicon-link"></span></a>Education</h3>

<ul>
<li>Ph.D, Computer Science (Vision and Graphics), 2015, Supervised by <a href="http://www.csis.hku.hk/people/profile.jsp?teacher=wenping">Prof. Wenping Wang</a>, <em>The University of Hong Kong (HKU)</em>.</li>
<li>B.Eng, Electronic Information Engineering, 2010, <em>University of Science and Technology of China (USTC)</em>.</li>
</ul>

<h3>
<a id="work-and-research-experiences" class="anchor" href="#work-and-research-experiences" aria-hidden="true"><span class="octicon octicon-link"></span></a>Work and Research Experiences</h3>

<p><strong>Staff Researcher, Lenovo</strong>. (April. 2015 - Now)</p>

<ul>
<li>
<strong>An Augmented Reality Application for Mobile Devices</strong>. (<a href="https://youtu.be/1yumrxOw1ck">Youtube</a>)

<ul>
<li>Developed an application providing augmented reality effect when camera previewing scenes containing QR code or a dish of food, to improve user experiences.</li>
<li>The application detects and tracks the features as well as estimates the camera poses by the 3D-2D perspective n-points correspondence algorithm. With the camera pose estimated for each frame, we render an virtual object by OpenGL for the scene.</li>
</ul>
</li>
</ul>

<p><img src="http://wangchuan.github.io/imgs/AR.gif" alt="ARDemo"></p>

<ul>
<li>
<strong>An Image Refocus Algorithm for Dual-camera Cellphone of Lenovo</strong>.

<ul>
<li>Developed an image refocus algorithm for Lenovo dual camera phone <a href="http://www.amazon.com/Lenovo-FREE-DUAL-SIM-5inch-LTE-1-7GHz-Processor-3GB/dp/B017U1OILI/ref=sr_1_1?ie=UTF8&amp;qid=1450273162&amp;sr=8-1&amp;keywords=vibe+s1">VIBE S1</a>, which is on sale in the market. </li>
<li>The algorithm uses the depth information captured by the dual camera to blur the image with a spatially-variant kernel if users specify a focus point when viewing the image. </li>
<li>To achieve real-time interaction, we utilized OpenCL to speed up the blurring process.</li>
</ul>
</li>
<li>
<strong>Speaker Identification via Deep Learning</strong>.

<ul>
<li>Co-developed a speaker identification system based on Recurrent Neural Network (RNN), specifically Long Short-Term Memory (LSTM) technique.</li>
<li>The system utilizes both face image and audio information in a video sequence to classify the speaker. The novelity lies in such a multi-modal LSTM solution. </li>
<li>Did experiments to demonstrate this solution can achieve higher precision than state-of-the-art Convolution Neural Network (CNN) based method, implemented based on Caffe. The paper was accepted in AAAI 2016.</li>
</ul>
</li>
</ul>

<p><strong>Ph.D, The University of Hong Kong</strong>. (Sep. 2010 - Jan. 2015)</p>

<ul>
<li>
<strong>Video Vectorization</strong>.

<ul>
<li>Proposed a vector-based representation, i.e. tetrahedral mesh, for raster video to achieve low storage with resolution-independent high quality of reconstruction. Also developed a system to convert a raster video into its vectorized version.</li>
<li>Developed a core algorithm for the system, i.e. a tetrahedral mesh simplification algorithm extended from the one for triangular mesh but handles more complicated topological cases. Also implemented subdivision and deformation algorithm for the tetrahedral mesh to preserve the features in the original video.</li>
<li>Developed a rasterization method to convert the vectorized version back, i.e. 1) slice the tetrahedral mesh into triangular meshes; 2) render each triangular mesh as each frame by OpenGL.</li>
<li>Designed a streaming strategy to process a video to achieve low memory cost but keeps the topology of the corresponding tetrahedral mesh.</li>
</ul>
</li>
<li>
<strong>Video Object Co-Segmentation</strong>.

<ul>
<li>Developed a common-foreground co-segmentation system for a group of videos automatically.</li>
<li>Proposed a novel customized subspace clustering algorithm to differentiate foreground and background within each video but correlate the common foreground in various videos. This algorithm takes advantage of appearance and motion features in the video group discriminatively, so as to outperform state-of-the-art methods. </li>
<li>To build up the system, utilized existing mature techniques like K-means algorithm, Gaussian Mixture Model, Bag-of-Words Model and Markov Random Field etc. The paper was published in TMM 2014.</li>
</ul>
</li>
<li>
<strong>Image Matting Application</strong>. ((Project Page)[<a href="https://bitbucket.org/wangchuan2400/robustmatting">https://bitbucket.org/wangchuan2400/robustmatting</a>])

<ul>
<li>Developed an interactive application to cut foreground from an image based on Robust Image Matting algorithm.</li>
</ul>
</li>
</ul>

<p><img src="http://wangchuan.github.io/imgs/matting.png" alt="matting"></p>

<h3>
<a id="skills" class="anchor" href="#skills" aria-hidden="true"><span class="octicon octicon-link"></span></a>Skills</h3>

<ul>
<li>Proficient in Native C/C++, MATLAB.</li>
<li>Proficient in OpenCV; Familiar with OpenGL; Experience of using OpenCL, CUDA, Boost, Intel MKL, CGAL etc.</li>
<li>Proficient in developing with Visual Studio in Windows; Experience of developing in Linux.</li>
<li>Familiar with using computer vision or machine learning related techniques such as CNN(Caffe), Optical/SIFT Flow, Image Deblurring, Calibration, Structure from Motion etc.</li>
<li>Familiar with .NET Framework, C#, WPF, Managed C++.</li>
<li>Familiar with GUI design in WPF or QT; Love designing applications with fancy GUI (e.g. <a href="http://i.cs.hku.hk/%7Ecwang/video_processing/">here</a> by C++/C#/WPF).</li>
<li>Familiar with using Microsoft Office, Adobe Photoshop/Illustrator/Premiere, MeshLab.</li>
</ul>

<hr>

<p><em>Last Update: Dec. 1, 2015</em></p>

      <footer class="site-footer">

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
